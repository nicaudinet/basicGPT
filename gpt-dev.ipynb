{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34b71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-14 16:41:04--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M   337KB/s    in 3.2s    \n",
      "\n",
      "2023-07-14 16:41:22 (337 KB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95832b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae7daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3d2558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8063542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28c203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "string2int = { ch:i for i,ch in enumerate(chars) }\n",
    "print(string2int[\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d91aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n"
     ]
    }
   ],
   "source": [
    "int2string = { i:ch for i,ch in enumerate(chars) }\n",
    "print(int2string[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b295ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43]\n"
     ]
    }
   ],
   "source": [
    "def encode(str):\n",
    "    return [string2int[c] for c in str]\n",
    "print(encode(\"hi there\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b1e24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there\n"
     ]
    }
   ],
   "source": [
    "def decode(tokenList):\n",
    "    return \"\".join([int2string[i] for i in tokenList])\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "267a4727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bbbfb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[n:]\n",
    "val_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad567cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12,  0,  0, 19, 30, 17, 25, 21, 27])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "print(train_data[:block_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "045b9911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: tensor([12]) - target: 0\n",
      "context: tensor([12,  0]) - target: 0\n",
      "context: tensor([12,  0,  0]) - target: 19\n",
      "context: tensor([12,  0,  0, 19]) - target: 30\n",
      "context: tensor([12,  0,  0, 19, 30]) - target: 17\n",
      "context: tensor([12,  0,  0, 19, 30, 17]) - target: 25\n",
      "context: tensor([12,  0,  0, 19, 30, 17, 25]) - target: 21\n",
      "context: tensor([12,  0,  0, 19, 30, 17, 25, 21]) - target: 27\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"context: {context} - target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6324e",
   "metadata": {},
   "source": [
    "### Generalization of the block_size which includes the batch dimension as well (used to keep the GPUs busy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df41d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([4, 8])\n",
      "tensor([[ 6,  1, 52, 53, 58,  1, 58, 47],\n",
      "        [ 6,  1, 54, 50, 39, 52, 58, 43],\n",
      "        [ 1, 58, 46, 47, 57,  1, 50, 47],\n",
      "        [ 0, 32, 46, 43, 56, 43,  1, 42]])\n",
      "Targets: torch.Size([4, 8])\n",
      "tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
      "        [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
      "        [58, 46, 47, 57,  1, 50, 47, 60],\n",
      "        [32, 46, 43, 56, 43,  1, 42, 53]])\n",
      "---\n",
      "tensor([6]) -> 1\n",
      "tensor([6, 1]) -> 52\n",
      "tensor([ 6,  1, 52]) -> 53\n",
      "tensor([ 6,  1, 52, 53]) -> 58\n",
      "tensor([ 6,  1, 52, 53, 58]) -> 1\n",
      "tensor([ 6,  1, 52, 53, 58,  1]) -> 58\n",
      "tensor([ 6,  1, 52, 53, 58,  1, 58]) -> 47\n",
      "tensor([ 6,  1, 52, 53, 58,  1, 58, 47]) -> 50\n",
      "tensor([6]) -> 1\n",
      "tensor([6, 1]) -> 54\n",
      "tensor([ 6,  1, 54]) -> 50\n",
      "tensor([ 6,  1, 54, 50]) -> 39\n",
      "tensor([ 6,  1, 54, 50, 39]) -> 52\n",
      "tensor([ 6,  1, 54, 50, 39, 52]) -> 58\n",
      "tensor([ 6,  1, 54, 50, 39, 52, 58]) -> 43\n",
      "tensor([ 6,  1, 54, 50, 39, 52, 58, 43]) -> 58\n",
      "tensor([1]) -> 58\n",
      "tensor([ 1, 58]) -> 46\n",
      "tensor([ 1, 58, 46]) -> 47\n",
      "tensor([ 1, 58, 46, 47]) -> 57\n",
      "tensor([ 1, 58, 46, 47, 57]) -> 1\n",
      "tensor([ 1, 58, 46, 47, 57,  1]) -> 50\n",
      "tensor([ 1, 58, 46, 47, 57,  1, 50]) -> 47\n",
      "tensor([ 1, 58, 46, 47, 57,  1, 50, 47]) -> 60\n",
      "tensor([0]) -> 32\n",
      "tensor([ 0, 32]) -> 46\n",
      "tensor([ 0, 32, 46]) -> 43\n",
      "tensor([ 0, 32, 46, 43]) -> 56\n",
      "tensor([ 0, 32, 46, 43, 56]) -> 43\n",
      "tensor([ 0, 32, 46, 43, 56, 43]) -> 1\n",
      "tensor([ 0, 32, 46, 43, 56, 43,  1]) -> 42\n",
      "tensor([ 0, 32, 46, 43, 56, 43,  1, 42]) -> 53\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Inputs:\", xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets:\", yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"{context} -> {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03f155",
   "metadata": {},
   "source": [
    "# BigramLanguageModel\n",
    "\n",
    "Use pytorch to implement a very simple neural network: the bigram language model.\n",
    "\n",
    "Make predictions with context 1. \"If I am token number 5, what comes next?\"\n",
    "\n",
    "Use negative log likelihood to measure loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70d99cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.4913, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # Create the logits from the embedding table\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Reshape to fit the cross-entropy function\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # Compute the loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "output = m.generate(idx, max_new_tokens=100)[0].tolist()\n",
    "print(decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b49c7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e610eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # Create the logits from the embedding table\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Reshape to fit the cross-entropy function\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # Compute the loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07d0f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3153867721557617\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "losses = []\n",
    "\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss)\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05129538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "PENDATI and hXsoughicer fare r\n",
      "\n",
      "CENSPRUMI.\n",
      "PRUMIO, binouricirre ncido she s wavavere f'd ot ory t.\n",
      "Bukinco'therelinorin ansous airsthethove inthec melllloine spelllorer, oout hope,\n",
      "Sit s.\n",
      "GO: hak! r!\n",
      "A t amam h t ghe,\n",
      "Bato ed bdr at, f, thast to Is he hiso se:\n",
      "Grouled per la memp y me avey p. ze it pped s hy to sikng\n",
      "en' pthis whaveewit the thithetuturd IOSine ma osanastormik y mupe s th y.\n",
      "o cest:\n",
      "\n",
      "\n",
      "Mielatoowis,Sy has; ls swht y and IO:\n",
      "UCENA bey y youinou wig by, mak'g t lea ere wer pedagon astof inill Pes?\n",
      "GRAn avener my kend ifrer ait cel nfy nouepem.\n",
      "beaished adand smangscke c vethes fond.\n",
      "\n",
      "Kak\n",
      "\n",
      "APETERONDETI youste n yor hean h ans pofin t our oucene.\n",
      "GRAn t as y, wif we:\n",
      "IO:\n",
      "IEve; beld bee:\n",
      "Kas mee fayou y ape p muc, beyo, f d atout'd frslefooinde, fe'd nddonole nte aisemeeth s coway tie.\n",
      "\n",
      "BAd:d.\n",
      "\n",
      "bl f torraze?\n",
      "Whe chre rr l'des an giou sstedad aterpe ow te! ak;\n",
      "\n",
      "\n",
      "TERUCH:\n",
      "\n",
      "\n",
      "\n",
      "Wierevecheer tr st ainjas t mesisheg bor mear.\n",
      "BA:\n",
      "fin ch wo ay manchithyo'tlerionghond me scan'eat: mav\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "output = m.generate(idx, max_new_tokens=100)[0].tolist()\n",
    "print(decode(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2556ab",
   "metadata": {},
   "source": [
    "# Mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65c19768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e32706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i <= t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdedc337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T)) # weights\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C) BATCH MATRIX MULTIPLY\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dbf40c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78a7100f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "293a1eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94d7730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones((3,3)))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1689f982",
   "metadata": {},
   "source": [
    "# Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0832530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ----> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "# out = wei @ x\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6d0bf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810677a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
